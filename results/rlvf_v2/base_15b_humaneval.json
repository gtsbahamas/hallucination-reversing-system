{
  "model": "bigcode/starcoder2-15b",
  "is_adapter": false,
  "elapsed_seconds": 7132.1566915512085,
  "evaluated_at": "2026-02-13T05:09:48Z",
  "humaneval": {
    "benchmark": "humaneval",
    "total_tasks": 164,
    "passed": 138,
    "pass_rate": 0.8414634146341463,
    "pass_rate_pct": "84.1%",
    "num_samples": 1,
    "results": [
      {
        "task_id": "HumanEval/0",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_has_close_elements.py\nfrom has_close_elements import has_close_elements\n\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/1",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/README.md\n# Python-Exercises\n\nThis repository contains a collection of Python exercises.\n\n## Installation\n\nTo install the exercises, clone this repository and run the following command:\n\n```bash\npip install -r requirements.txt\n```\n\n## Usage\n\nTo run the exercises, open a terminal and navigate to the directory where the exercises are located.\n\n## Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nPlease make sure to up",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/2",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/3",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_below_zero.py\nfrom below_zero import below_zero\n\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/4",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/exercises/practice/perfect-numbers/perfect_numbers.py\nfrom typing import List\n\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/5",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/python_practice/pyt",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/6",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/src/main/python/com/skalicky/python/interviewpuzzles/find_duplicate_files.py\nfrom typing import List\n\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/7",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_task_003.py\nimport pytest\n\nfrom tasks.task_003 import is_palindrome\n\n\n@pytest.mark.parametrize('string, expected', [\n    ('', True),\n    ('a', True),\n    ('ab', False),\n    ('aba', True),\n    ('abba', True),\n    ('abcba', True),\n    ('abccba', True),\n    ('abccbb', False),\n    ('abccbbaa', False),\n    ('abccbbaaa', False),\n    ('abccbbaaaa', False),\n    ('abccbbaaaaa', False),\n    ('abccbbaaaaaa', False),\n    ('abccbbaaaaaaa', False),\n    ('abccbbaaaaaaaa', False),\n    ('abccbbaaaaaa",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/8",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_task_0001.py\nimport pytest\n\nfrom tasks.task_0001 import sum_product\n\n\n@pytest.mark.parametrize(\n    \"numbers, expected\",\n    [\n        ([], (0, 1)),\n        ([1, 2, 3, 4], (10, 24)),\n    ],\n)",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/9",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/10",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "#    if is_palindrome(string):\n#        return string\n    # Find the longest palindrome suffix\n    for i in range(len(string), 0, -1):\n        if is_palindrome(string[-i:]):\n            break\n    # Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n    return string + string[-i:-1][::-1]\n\n",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/11",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/12",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/03_functions/02_functions_with_parameters.py\n# Functions with parameters\n#\n# Functions can take parameters.\n#\n# Parameters are variables that are only visible inside the function.\n#\n# Parameters are specified after the function name, inside the parentheses.\n#\n# You can add as many parameters as you want, just separate them with a comma.\n#\n# The following example has a function with one parameter (fname). When the function is called, we pass along a first name, which is used inside the fu",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/13",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/14",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/15",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/16",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/17",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/01_python_basics/01_basics/01_basics.py\n# 1. Write a function that takes a list of numbers and returns a new list with only the even numbers.\n#\n# >>> even_numbers([1, 2, 3, 4, 5, 6, 7, 8, 9])\n# [2, 4, 6, 8]\n#\n# >>> even_numbers([1, 3, 5, 7, 9])\n# []\n#\n# >>> even_numbers([])\n# []\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/18",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/19",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/20",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_exercise_01.py\nimport pytest\n\nfrom exercises.exercise_01 import find_closest_elements\n\n\n@pytest.mark.parametrize(\n    \"numbers, expected\",\n    [\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.2], (2.0, 2.2)),\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], (2.0, 2.0)),\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.1], (2.0, 2.1)),\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.3], (2.0, 2.3)),\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.4], (2.0, 2.4)),\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 2.5], (2.0, 2.5)),\n        ([1.0, 2.0,",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/21",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/22",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/tests/test_task_01_filter_integers.py\nimport pytest\n\nfrom tasks.task_01_filter_integers import filter_integers\n\n\n@pytest.mark.parametrize(\n    'values, expected',\n    [\n        (['a', 3.14, 5], [5]),\n        ([1, 2, 3, 'abc', {}, []], [1, 2, 3]),\n    ]\n)",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/23",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/24",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/25",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/homework01/task03.py",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/26",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/exercises/ex02/test_ex02.py\nimport pytest\nfrom ex02 import *\n\n# test for exercise 2.1",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/27",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/28",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/exercises/01-basic-types/01-02-string-methods/test_string_methods.py\nfrom string_methods import *\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/29",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/exercises/practice/triangle/.approaches/introduction.md\n# Introduction\n\nThere are a few different ways to solve Triangle.\nOne approach is to use a [dictionary][dictionary] to map the sides to the type of triangle.\n\nFor example, given the sides `2`, `2`, and `2`, the [dictionary][dictionary] would look like:\n\n```python\n{\n    (2, 2, 2): 'equilateral',\n    (2, 2, 3): 'isosceles',\n    (2, 3, 4):'scalene'\n}\n```\n\nThe keys are the sides of the triangle, and the values are the type of triangle.\n\nTo det",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/30",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/31",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/32",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/README.md\n# Python-Projects\n\nThis repository contains a collection of Python projects.\n\n## Projects\n\n- [Polynomial Zero Finder](https://github.com/sahil-kale/Python-Projects/tree/main/Polynomial%20Zero%20Finder)\n- [Tic Tac Toe](https://github.com/sahil-kale/Python-Projects/tree/main/Tic%20Tac%20Toe)\n- [Hangman](https://github.com/sahil-kale/Python-Projects/tree/main/Hangman)\n- [Rock Paper Scissors](https://github.com/sahil-kale/Python-Projects/tree/main/Rock%20Paper%20Scissors)\n- [Blackjack](ht",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/33",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/34",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/35",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/36",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/37",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/38",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "#     groups = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)]\n#     groups = [(group[-1] + group[:-1]) if len(group) == 3 else group for group in groups]\n#     return \"\".join(groups)\n    return encode_cyclic(s)\n\n",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/39",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/40",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/41",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/42",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/43",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/44",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/45",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/46",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/47",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/48",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/49",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/50",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "#     return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\n",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/51",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/52",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/53",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/54",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/55",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/56",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/57",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/58",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/59",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/60",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/61",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/62",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/63",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/64",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/65",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/66",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/67",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/68",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/69",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/70",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/71",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/72",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/73",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/74",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/75",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/76",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/77",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/78",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/79",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/80",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/81",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/82",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/83",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/84",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "\nif __name__ == \"__main__\":\n    N = int(input())\n    print(solve(N))/Python/CodeSignal/Arcade/Intro/13_reverseParentheses.py",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/85",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/86",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/87",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/88",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/89",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/90",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/91",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/92",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/93",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/94",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/95",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/96",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/97",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/98",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/99",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/100",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "\n#    if n % 2 == 0:\n#        return [n] + make_a_pile(n + 2)\n#    else:\n#        return [n] + make_a_pile(n + 1)\n\n    return [n] + make_a_pile(n + 1 + n % 2)\n\n",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/101",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/102",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/103",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/104",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/105",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/106",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/107",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/108",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/109",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/110",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/111",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/112",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/113",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/114",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/115",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/116",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/kyu_5/count_ip_addresses.py\n\"\"\"\nWrite a function that accepts a starting and ending IPv4 address, and returns\nhow many IP addresses come after the starting address up to but not including\nthe end address.\n\nAll inputs will be valid IPv4 addresses in the form of strings. The ending\naddress will be at least one address higher than the starting address.\n\nExamples:\n>>> count_ip_addresses(\"10.0.0.0\", \"10.0.0.50\") == 50\n>>> count_ip_addresses(\"10.0.0.0\", \"10.0.1.0\") == 256\n>>> count_ip_addresse",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/117",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/118",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/119",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/120",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/121",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/122",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/tests/test_arrays.py\nimport pytest\n\nfrom python.arrays import (\n    add_elements,\n    find_max_sum_subarray,\n    find_max_sum_subarray_brute_force,\n    find_max_sum_subarray_kadane,\n    find_max_sum_subarray_kadane_optimized,\n    find_max_sum_subarray_naive,\n    find_max_sum_subarray_naive_optimized,\n    find_max_sum_subarray_sliding_window,\n    find_max_sum_subarray_sliding_window_optimized,\n    find_max_sum_subarray_sliding_window_optimized_2,\n    find_max_sum_subarray_sliding_window_o",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/123",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/124",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/125",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/126",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/127",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/128",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/129",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/130",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/131",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/132",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/133",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/134",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/135",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/01_warmup/warmup_01.py\n\"\"\"Warmup-1 > sleep_in\n\nThe parameter weekday is True if it is a weekday, and the parameter vacation\nis True if we are on vacation. We sleep in if it is not a weekday or we're on\nvacation. Return True if we sleep in.\n\nsleep_in(False, False) \u2192 True\nsleep_in(True, False) \u2192 False\nsleep_in(False, True) \u2192 True\n\"\"\"\n\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/136",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/137",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/138",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/139",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/140",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/141",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "\n# 3. Write a function which takes a string representing a file's name, and returns\n# 'Yes' if the the file's name is valid, and returns 'No' otherwise.\n# A file's name is considered to be valid if and only if all the following conditions \n# are met:\n# - There should not be more than three digits ('0'-'9') in the file's name.\n# - The file's name contains exactly one dot '.'\n# - The substring before the dot should not be empty, and it starts with a letter from \n# the latin alphapet ('a'-'z' and '",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/142",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/143",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/problems/0001_two_sum/two_sum.py",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/144",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/145",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/homeworks/hw1/task1.py",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/146",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/147",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/148",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/149",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/week-04/day-01/01-sum-all.py\n# - Create a variable named `ai`\n#   with the following content: `[3, 4, 5, 6, 7]`\n# - Log the sum of the elements in `ai` to the console\n\nai = [3, 4, 5, 6, 7]\n\nprint(sum(ai))\n/week-03/day-04/01-copy-file.py\n# Write a function that copies the contents of a file into another\n# It should take the filenames as parameters\n# It should return a boolean that shows if the copy was successful\n",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/150",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/151",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/152",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/153",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/154",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/155",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/156",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/157",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/158",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "/python/01_basics/02_data_types/02_strings/02_string_methods.py\n\"\"\"\nString Methods\n\nStrings have a bunch of built-in methods that can be used to manipulate them.\n\nSome of the most common string methods are:\n\n* len(string) - returns the length of the string\n* lower() - returns the string in all lowercase\n* upper() - returns the string in all uppercase\n* capitalize() - returns the string with the first character capitalized\n* count(substring) - returns the number of times the substring appears in ",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/159",
        "passed": false,
        "completions": [
          {
            "sample": 0,
            "completion": "\n# Write your code here\n\n# Test\nprint(eat(5, 6, 10))\nprint(eat(4, 8, 9))\nprint(eat(1, 10, 10))\nprint(eat(2, 11, 5))\n/README.md\n# Python-Exercises\n\nThis repository contains a set of exercises for Python beginners.\n\n## How to use\n\n* Clone this repository\n* Open the folder\n* Open the file that you want to solve\n* Solve the problem\n* Run the file\n* Check the result\n\n## Exercises\n\n* [Eat](https://github.com/Amine-Smahi/Python-Exercises/blob/master/Eat.py)\n* [Sum](https://github.com/Amine-Smahi/Python",
            "correct": false
          }
        ]
      },
      {
        "task_id": "HumanEval/160",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/161",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/162",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      },
      {
        "task_id": "HumanEval/163",
        "passed": true,
        "completions": [
          {
            "sample": 0,
            "completion": "",
            "correct": true
          }
        ]
      }
    ]
  }
}