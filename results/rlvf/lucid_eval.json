{
  "total_tasks": 164,
  "passed": 141,
  "pass_rate": 0.8597560975609756,
  "pass_rate_pct": "86.0%",
  "num_samples": 1,
  "results": [
    {
      "task_id": "HumanEval/0",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_has_close_elements.py\nfrom unittest import TestCase\n\nfrom src.has_close_elements import has_close_elements\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/1",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/2",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/3",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/python/0001-0099/0047-permutations-ii.py\nfrom typing import List\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/4",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_mean_absolute_deviation.py\nfrom mean_absolute_deviation import mean_absolute_deviation\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/5",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/6",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/src/problems/leetcode/0012_integer_to_roman.py\n\"\"\"\nhttps://leetcode.com/problems/integer-to-roman/\n\nGiven an integer, convert it to a roman numeral.\n\nInput is guaranteed to be within the range from 1 to 3999.\n\"\"\"\nfrom typing import Dict\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/7",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_filter_by_substring.py\nfrom filter_by_substring import filter_by_substring\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/8",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/9",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_rolling_max.py\nfrom rolling_max import rolling_max\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/10",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     if not string:\n#         return string\n#     if is_palindrome(string):\n#         return string\n#     prefix = find_longest_prefix(string)\n#     return prefix + make_palindrome(prefix[::-1])\n    if not string:\n        return string\n    if is_palindrome(string):\n        return string\n    prefix = find_longest_prefix(string)\n    return prefix + make_palindrome(prefix[::-1])\n\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/11",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/12",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_01_basics.py\nimport pytest\n\nfrom basics import (\n    add,\n    add_all,\n    add_all_even,\n    add_all_odd,\n    add_all_positive,\n    add_all_positive_and_negative,\n    add_all_positive_and_negative_and_zero,\n    add_all_positive_and_zero,\n    add_all_positive_and_zero_and_negative,\n    add_all_positive_and_zero_and_negative_and_positive,\n    add_all_positive_and_zero_and_negative_and_positive_and_negative,\n    add_all_positive_and_zero_and_negative_and_positive_and_negative_and_zero,\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/13",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/14",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/15",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/16",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/17",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_01_parse_music.py\nfrom unittest import TestCase\n\nfrom solutions.01_parse_music import parse_music\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/18",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/19",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/20",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_find_closest_elements.py\nfrom unittest import TestCase\n\nfrom src.find_closest_elements import find_closest_elements\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/21",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     assert len(numbers) >= 2, \"List must have at least two elements\"\n    numbers = sorted(numbers)\n    return [number / numbers[-1] for number in numbers]\n\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/22",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_filter_integers.py\nfrom unittest import TestCase\n\nfrom src.filter_integers import filter_integers\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/23",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/24",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/25",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/26",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_001_remove_duplicates.py\nimport pytest\n\nfrom src.001_remove_duplicates import remove_duplicates\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/27",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/28",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_01_strings.py\nimport unittest\n\nfrom src.strings import concatenate\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/29",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/tests/test_filter_by_prefix.py\nfrom filter_by_prefix import filter_by_prefix\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/30",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/31",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#    if n == 1:\n#        return False\n#    if n == 2:\n#        return True\n#    for i in range(2, n):\n#        if n % i == 0:\n#            return False\n#    return True\n    if n == 1:\n        return False\n    for i in range(2, int(math.sqrt(n)) + 1):\n        if n % i == 0:\n            return False\n    return True\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/32",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/README.md\n# Algorithms\n\nThis repository contains implementations of some algorithms and data structures.\n\n## Algorithms\n\n- [Binary search](https://github.com/sourabh-kumar/algorithms/blob/master/binary_search.py)\n- [Bisection method](https://github.com/sourabh-kumar/algorithms/blob/master/bisection_method.py)\n- [Interpolation search](https://github.com/sourabh-kumar/algorithms/blob/master/interpolation_search.py)\n- [Newton's method](https://github.com/sourabh-kumar/algorithms/blob/master/newton",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/33",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/34",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/35",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/36",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/37",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/38",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     # split string to groups. Each of length 3.\n    groups = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)]\n    # cycle elements in each group. Unless group has fewer elements than 3.\n    groups = [(group[1:] + group[0]) if len(group) == 3 else group for group in groups]\n    return \"\".join(groups)\n\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/39",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/40",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/41",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/42",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/43",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/44",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     if base < 2 or base > 10:\n#         raise ValueError('base must be between 2 and 10')\n    if base < 2 or base > 10:\n        return ValueError('base must be between 2 and 10')\n    if x < 0:\n        return ValueError('x must be non-negative')\n    if x == 0:\n        return '0'\n    result = ''\n    while x > 0:\n        result = str(x % base) + result\n        x = x // base\n    return result\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/45",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/46",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/47",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/48",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/49",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/50",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/51",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#     return text.translate(str.maketrans('', '', 'aeiouAEIOU'))\n    return ''.join([c for c in text if c not in 'aeiouAEIOU'])\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/52",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/53",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/54",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/55",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/56",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/57",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/58",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/59",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/60",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/61",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/62",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/63",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/64",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/65",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/66",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/67",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/68",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/69",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/70",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/71",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/72",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/73",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/74",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/75",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/76",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/77",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/78",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/79",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/80",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/81",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/82",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/83",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/84",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "\nif __name__ == \"__main__\":\n    print(solve(1000))\n    print(solve(150))\n    print(solve(147))\n/src/leetcode/0001-two-sum.py\n\"\"\"\nGiven an array of integers, return indices of the two numbers such that they add up to a specific target.\n\nYou may assume that each input would have exactly one solution, and you may not use the same element twice.\n\nExample:\n\nGiven nums = [2, 7, 11, 15], target = 9,\n\nBecause nums[0] + nums[1] = 2 + 7 = 9,\nreturn [0, 1].\n\"\"\"\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/85",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/86",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/87",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/88",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/89",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/90",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/91",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/92",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/93",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/94",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/95",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/96",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/97",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/98",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/99",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/100",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/101",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/102",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/103",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/104",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/105",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/106",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/107",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/leetcode/0001-0099/0059_spiral_matrix_ii.py\n\"\"\"\n59. Spiral Matrix II\n\nGiven a positive integer n, generate a square matrix filled with elements from 1 to n2 in spiral order.\n\nExample:\n\nInput: 3\nOutput:\n[\n [ 1, 2, 3 ],\n [ 8, 9, 4 ],\n [ 7, 6, 5 ]\n]\n\"\"\"\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/108",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/109",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/110",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/111",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/112",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/113",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/114",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/115",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/116",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/codewars/python/6kyu/find_the_odd_int.py\n\"\"\"\nGiven an array of integers, find the one that appears an odd number of times.\n\nThere will always be only one integer that appears an odd number of times.\n\"\"\"\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/117",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/118",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/119",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/120",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/problems/0001-0099/0021-merge-two-sorted-lists/merge-two-sorted-lists.py\n# Definition for singly-linked list.\n# class ListNode:\n#     def __init__(self, val=0, next=None):\n#         self.val = val\n#         self.next = next",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/121",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/122",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/123",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/124",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/125",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/126",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/127",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/128",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/129",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/src/leetcode/0001-0099/0041-first-missing-positive.py",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/130",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/README.md\n# Codewars\n\nThis repository contains my solutions to the [Codewars](https://www.codewars.com/) challenges.\n\n## Table of Contents\n\n- [Codewars](#codewars)\n  - [Table of Contents](#table-of-contents)\n  - [Challenges](#challenges)\n    - [8 kyu](#8-kyu)\n    - [7 kyu](#7-kyu)\n    - [6 kyu](#6-kyu)\n    - [5 kyu](#5-kyu)\n    - [4 kyu](#4-kyu)\n    - [3 kyu](#3-kyu)\n    - [2 kyu](#2-kyu)\n    - [1 kyu](#1-kyu)\n\n## Challenges\n\n### 8 kyu\n\n| Name                                                    ",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/131",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/132",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/133",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/134",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/135",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/136",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/137",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/138",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/139",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/140",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/141",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/142",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "\n#     if len(lst) == 0:\n#         return 0\n#     else:\n#         sum_ = 0\n#         for i in range(len(lst)):\n#             if i % 3 == 0:\n#                 sum_ += lst[i]**2\n#             elif i % 4 == 0 and i % 3!= 0:\n#                 sum_ += lst[i]**3\n#         return sum_\n\n\n#     sum_ = 0\n#     for i in range(len(lst)):\n#         if i % 3 == 0:\n#             sum_ += lst[i]**2\n#         elif i % 4 == 0 and i % 3!= 0:\n#             sum_ += lst[i]**3\n#     return sum_\n\n\n#     sum_ = 0\n#     f",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/143",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/python/0001_two_sum.py\nfrom typing import List\n\n",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/144",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/145",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/146",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/147",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/148",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/149",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/150",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/151",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/152",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/153",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/154",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/155",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/156",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/157",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/158",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/159",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/160",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/161",
      "passed": false,
      "completions": [
        {
          "sample": 0,
          "completion": "/python/src/codewars/kyu_6/find_the_odd_int.py",
          "correct": false
        }
      ]
    },
    {
      "task_id": "HumanEval/162",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "#    return hashlib.md5(text.encode('utf-8')).hexdigest()\n    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
          "correct": true
        }
      ]
    },
    {
      "task_id": "HumanEval/163",
      "passed": true,
      "completions": [
        {
          "sample": 0,
          "completion": "",
          "correct": true
        }
      ]
    }
  ],
  "model": "models/lucid",
  "is_adapter": true,
  "elapsed_seconds": 10542.880140781403,
  "evaluated_at": "2026-02-12T08:17:57Z"
}