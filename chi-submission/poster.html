<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>LUCID: Using LLM Hallucination as a Tool for Thought in Software Specification</title>
<style>
  @page {
    size: landscape;
    margin: 0;
  }

  * {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }

  body {
    font-family: 'Georgia', 'Times New Roman', serif;
    background: #0d1117;
    color: #e6edf3;
    width: 100%;
    max-width: 1400px;
    margin: 0 auto;
    padding: 0;
    -webkit-print-color-adjust: exact;
    print-color-adjust: exact;
  }

  /* ---- HEADER ---- */
  .poster-header {
    background: linear-gradient(135deg, #1a1f2e 0%, #0d1117 50%, #161b22 100%);
    border-bottom: 4px solid #58a6ff;
    padding: 28px 40px 22px;
    text-align: center;
  }

  .poster-header h1 {
    font-size: 26px;
    font-weight: 700;
    color: #ffffff;
    letter-spacing: 0.3px;
    line-height: 1.3;
    margin-bottom: 4px;
  }

  .poster-header h1 em {
    color: #58a6ff;
    font-style: normal;
  }

  .poster-header .subtitle {
    font-size: 14px;
    color: #8b949e;
    margin-bottom: 8px;
    font-style: italic;
  }

  .poster-header .author-line {
    font-size: 14px;
    color: #c9d1d9;
    margin-bottom: 2px;
  }

  .poster-header .venue {
    font-size: 12px;
    color: #58a6ff;
    font-weight: 600;
    letter-spacing: 1px;
    text-transform: uppercase;
    margin-top: 6px;
  }

  .poster-header .links {
    font-size: 11px;
    color: #8b949e;
    margin-top: 4px;
  }

  .poster-header .links a {
    color: #58a6ff;
    text-decoration: none;
  }

  /* ---- GRID LAYOUT ---- */
  .poster-grid {
    display: grid;
    grid-template-columns: 1fr 1fr 1fr;
    gap: 0;
    padding: 16px 20px 12px;
  }

  .column {
    padding: 0 10px;
  }

  .column:first-child { padding-left: 0; }
  .column:last-child { padding-right: 0; }
  .column:not(:last-child) { border-right: 1px solid #21262d; }

  /* ---- SECTIONS ---- */
  .section {
    margin-bottom: 14px;
    padding: 12px 14px;
    background: #161b22;
    border-radius: 6px;
    border: 1px solid #21262d;
  }

  .section:last-child {
    margin-bottom: 0;
  }

  .section-title {
    font-size: 12px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: #58a6ff;
    margin-bottom: 8px;
    padding-bottom: 4px;
    border-bottom: 1px solid #21262d;
  }

  .section p, .section li {
    font-size: 11.5px;
    line-height: 1.55;
    color: #c9d1d9;
  }

  .section p + p {
    margin-top: 6px;
  }

  .section ul, .section ol {
    padding-left: 18px;
    margin-top: 4px;
  }

  .section li {
    margin-bottom: 3px;
  }

  .section strong {
    color: #e6edf3;
  }

  /* ---- HIGHLIGHT BOX ---- */
  .highlight-box {
    background: #1c2333;
    border-left: 3px solid #58a6ff;
    padding: 8px 12px;
    margin: 8px 0;
    font-style: italic;
    font-size: 11.5px;
    color: #e6edf3;
    border-radius: 0 4px 4px 0;
  }

  .highlight-box strong {
    color: #58a6ff;
    font-style: normal;
  }

  /* ---- CYCLE STEPS ---- */
  .cycle-steps {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 4px 10px;
    margin-top: 6px;
  }

  .cycle-step {
    display: flex;
    align-items: flex-start;
    gap: 6px;
    font-size: 11px;
    line-height: 1.4;
    color: #c9d1d9;
    padding: 3px 0;
  }

  .cycle-step .step-num {
    background: #58a6ff;
    color: #0d1117;
    font-weight: 700;
    font-size: 10px;
    min-width: 18px;
    height: 18px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 50%;
    flex-shrink: 0;
    margin-top: 1px;
  }

  .cycle-step .step-label {
    font-weight: 700;
    color: #e6edf3;
  }

  /* ---- TABLES ---- */
  table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 6px;
    font-size: 11px;
  }

  th {
    background: #1c2333;
    color: #58a6ff;
    font-weight: 700;
    text-align: left;
    padding: 5px 8px;
    font-size: 10.5px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    border-bottom: 2px solid #30363d;
  }

  td {
    padding: 4px 8px;
    border-bottom: 1px solid #21262d;
    color: #c9d1d9;
  }

  tr:last-child td {
    border-bottom: none;
  }

  /* Convergence table special styling */
  .convergence-table tr:last-child td {
    font-weight: 700;
    color: #3fb950;
  }

  .convergence-table td:last-child {
    font-weight: 600;
  }

  /* ---- DESIGN PRINCIPLES ---- */
  .principle {
    margin-bottom: 6px;
    padding-left: 8px;
    border-left: 2px solid #30363d;
  }

  .principle:last-child {
    margin-bottom: 0;
  }

  .principle .principle-title {
    font-weight: 700;
    font-size: 11.5px;
    color: #e6edf3;
  }

  .principle p {
    font-size: 11px;
    color: #8b949e;
    margin-top: 1px;
  }

  /* ---- NOVEL LIST ---- */
  .novel-item {
    display: flex;
    align-items: flex-start;
    gap: 6px;
    margin-bottom: 4px;
    font-size: 11.5px;
  }

  .novel-item::before {
    content: "\2713";
    color: #3fb950;
    font-weight: 700;
    flex-shrink: 0;
    margin-top: 1px;
  }

  /* ---- DISCUSSION QUESTIONS ---- */
  .question {
    font-size: 11px;
    color: #c9d1d9;
    padding: 4px 0 4px 10px;
    border-left: 2px solid #58a6ff;
    margin-bottom: 5px;
    font-style: italic;
  }

  .question:last-child {
    margin-bottom: 0;
  }

  /* ---- REFERENCES ---- */
  .references {
    font-size: 9.5px;
    color: #8b949e;
    line-height: 1.5;
    column-count: 2;
    column-gap: 16px;
  }

  .references p {
    font-size: 9.5px;
    color: #8b949e;
    margin-bottom: 2px;
    text-indent: -12px;
    padding-left: 12px;
  }

  /* ---- FOOTER ---- */
  .poster-footer {
    background: #161b22;
    border-top: 2px solid #21262d;
    padding: 8px 40px;
    text-align: center;
    font-size: 10px;
    color: #8b949e;
  }

  .poster-footer strong {
    color: #58a6ff;
  }

  /* ---- PARADIGM COMPARISON ---- */
  .paradigm-compare {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 8px;
    margin-top: 6px;
  }

  .paradigm-box {
    padding: 8px 10px;
    border-radius: 4px;
    font-size: 11px;
    line-height: 1.4;
  }

  .paradigm-old {
    background: #2d1b1b;
    border: 1px solid #f85149;
    color: #f0d0cc;
  }

  .paradigm-old .paradigm-label {
    color: #f85149;
    font-weight: 700;
    font-size: 10px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 3px;
  }

  .paradigm-new {
    background: #1b2d1b;
    border: 1px solid #3fb950;
    color: #d0f0cc;
  }

  .paradigm-new .paradigm-label {
    color: #3fb950;
    font-weight: 700;
    font-size: 10px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 3px;
  }

  /* ---- STATS ROW ---- */
  .stats-row {
    display: grid;
    grid-template-columns: repeat(4, 1fr);
    gap: 6px;
    margin-top: 8px;
  }

  .stat {
    text-align: center;
    padding: 6px 4px;
    background: #1c2333;
    border-radius: 4px;
  }

  .stat-value {
    font-size: 18px;
    font-weight: 700;
    color: #58a6ff;
    line-height: 1;
  }

  .stat-label {
    font-size: 9px;
    color: #8b949e;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-top: 2px;
  }

  /* ---- PRINT ---- */
  @media print {
    @page {
      size: 14in 8.5in landscape;
      margin: 0.25in;
    }

    body {
      background: #0d1117;
      width: 100%;
      max-width: none;
    }

    .poster-grid {
      padding: 12px 16px 8px;
    }

    .section {
      break-inside: avoid;
    }
  }
</style>
</head>
<body>

<!-- ==================== HEADER ==================== -->
<header class="poster-header">
  <h1>The <em>Lucid</em> Developer: Using LLM Hallucination as a<br>Tool for Thought in Software Specification</h1>
  <div class="subtitle">LUCID: Leveraging Unverified Claims Into Deliverables</div>
  <div class="author-line"><strong>Ty Wells</strong> &nbsp;|&nbsp; Independent Researcher &nbsp;|&nbsp; ty@snapperland.com</div>
  <div class="venue">CHI 2026 &mdash; Tools for Thought Workshop</div>
  <div class="links">GitHub: github.com/gtsbahamas/hallucination-reversing-system &nbsp;&bull;&nbsp; DOI: 10.5281/zenodo.18522644</div>
</header>

<!-- ==================== THREE-COLUMN GRID ==================== -->
<div class="poster-grid">

  <!-- ========== COLUMN 1 ========== -->
  <div class="column">

    <!-- Problem / Motivation -->
    <div class="section">
      <div class="section-title">Problem / Motivation</div>
      <p>AI coding assistants (Copilot, Cursor, Claude Code) treat hallucination as a <strong>failure mode</strong>. Developers manually inspect AI output, discarding or fixing hallucinated content. This places the full cognitive burden of verification on the developer.</p>
      <p>Three independent formal proofs establish that hallucination <strong>cannot be eliminated</strong> from LLMs &mdash; it is mathematically intrinsic (Xu 2024, Banerjee 2024, Karpowicz 2025).</p>
      <div class="highlight-box">
        If hallucination is inevitable, fighting it is the wrong strategy.<br>
        <strong>What if we harness it instead?</strong>
      </div>
    </div>

    <!-- Key Insight -->
    <div class="section">
      <div class="section-title">Key Insight</div>
      <p>Hallucination is computationally identical to the brain's <strong>pattern completion</strong> mechanism. In predictive processing (the dominant framework in cognitive neuroscience), all perception is "controlled hallucination" (Seth 2021, Clark 2023).</p>
      <p>The brain generates predictions, then constrains them with sensory data. LLMs do the same &mdash; they generate predictions, constrained (or unconstrained) by context.</p>
      <div class="highlight-box">
        <strong>LUCID</strong> treats hallucination the way the brain treats its own predictions: generate freely, then constrain iteratively.
      </div>
    </div>

    <!-- The Tool: LUCID -->
    <div class="section">
      <div class="section-title">The Tool: LUCID</div>
      <p><strong>Leveraging Unverified Claims Into Deliverables</strong> &mdash; a 6-phase iterative cycle:</p>
      <div class="cycle-steps">
        <div class="cycle-step"><span class="step-num">1</span><span><span class="step-label">Describe</span> &mdash; Provide deliberately incomplete app description</span></div>
        <div class="cycle-step"><span class="step-num">2</span><span><span class="step-label">Hallucinate</span> &mdash; LLM writes Terms of Service for the app</span></div>
        <div class="cycle-step"><span class="step-num">3</span><span><span class="step-label">Extract</span> &mdash; Parse each claim into a testable requirement</span></div>
        <div class="cycle-step"><span class="step-num">4</span><span><span class="step-label">Build</span> &mdash; Implement using claims as acceptance criteria</span></div>
        <div class="cycle-step"><span class="step-num">5</span><span><span class="step-label">Converge</span> &mdash; Verify claims against actual codebase</span></div>
        <div class="cycle-step"><span class="step-num">6</span><span><span class="step-label">Regenerate</span> &mdash; Feed verified reality back to model</span></div>
      </div>
      <p style="margin-top: 8px; font-size: 11px;"><strong>Why Terms of Service?</strong> Legal language forces precision across every dimension: functionality, security, privacy, performance, operations, compliance. A single hallucination produces 80&ndash;150 testable claims in 30 seconds.</p>
    </div>

    <!-- Theoretical Grounding -->
    <div class="section">
      <div class="section-title">Theoretical Grounding</div>
      <table>
        <thead>
          <tr><th>Neuroscience</th><th>LUCID Design</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>Predictive processing: perception = controlled hallucination</td>
            <td>Hallucinate freely, then constrain with verification</td>
          </tr>
          <tr>
            <td>Confabulation: generation &amp; checking are separable (Hirstein 2005)</td>
            <td>LLM generates; codebase verification checks</td>
          </tr>
          <tr>
            <td>Lucid dreaming: metacognition within generation (Baird 2019)</td>
            <td>Developer navigates hallucinated space with awareness</td>
          </tr>
          <tr>
            <td>System 1 / System 2 (Kahneman 2011)</td>
            <td>LLM = System 1; LUCID verification = System 2</td>
          </tr>
          <tr>
            <td>Protein hallucination: neural net dreams as blueprints (Nobel 2024)</td>
            <td>Software hallucination: LLM dreams as specifications</td>
          </tr>
        </tbody>
      </table>
    </div>

  </div>

  <!-- ========== COLUMN 2 ========== -->
  <div class="column">

    <!-- Convergence Results -->
    <div class="section">
      <div class="section-title">Convergence Results</div>
      <p>Applied to a production Next.js app (~30K lines, 200+ files):</p>
      <table class="convergence-table">
        <thead>
          <tr><th>Iteration</th><th>Compliance Score</th></tr>
        </thead>
        <tbody>
          <tr><td>1</td><td>~35% (est.)</td></tr>
          <tr><td>3</td><td>57.3%</td></tr>
          <tr><td>4</td><td>69.8%</td></tr>
          <tr><td>5</td><td>83.2%</td></tr>
          <tr><td>6</td><td>90.8%</td></tr>
        </tbody>
      </table>
      <div class="stats-row">
        <div class="stat">
          <div class="stat-value">91</div>
          <div class="stat-label">Claims Extracted</div>
        </div>
        <div class="stat">
          <div class="stat-value">5</div>
          <div class="stat-label">Categories</div>
        </div>
        <div class="stat">
          <div class="stat-value">$17</div>
          <div class="stat-label">Total Cost</div>
        </div>
        <div class="stat">
          <div class="stat-value">90.8%</div>
          <div class="stat-label">Final Score</div>
        </div>
      </div>
      <p style="margin-top: 8px; font-size: 10.5px; color: #8b949e;">Claim categories: Functionality (34), Security (18), Data Privacy (16), Operational (12), Legal Compliance (11). 5 remaining FAILs = genuine missing features, not false positives. Monotonic convergence (score never decreases).</p>
    </div>

    <!-- How This Is a "Tool for Thought" -->
    <div class="section">
      <div class="section-title">How This Is a "Tool for Thought"</div>
      <p>LUCID reframes the developer's cognitive role:</p>
      <div class="paradigm-compare">
        <div class="paradigm-box paradigm-old">
          <div class="paradigm-label">Current Paradigm</div>
          "Is this AI-generated code correct?"<br>
          <em>(line-by-line verification &mdash; exhausting, error-prone)</em>
        </div>
        <div class="paradigm-box paradigm-new">
          <div class="paradigm-label">LUCID Paradigm</div>
          "What does the AI think my app should be?"<br>
          <em>(specification-level exploration &mdash; higher abstraction)</em>
        </div>
      </div>
      <p style="margin-top: 8px;">The developer becomes a <strong>lucid dreamer</strong>: participating in AI hallucination with metacognitive awareness, harvesting useful specifications while maintaining the ability to distinguish generated from real.</p>
      <p>This is Engelbart's "augmenting human intellect" applied to the hallucination problem: the tool augments specification thinking by <strong>exploiting, not suppressing</strong>, the AI's generative tendency.</p>
    </div>

    <!-- Design Principles -->
    <div class="section">
      <div class="section-title">Design Principles for Hallucination-Aware Tools</div>
      <div class="principle">
        <div class="principle-title">1. Separate generation from verification</div>
        <p>Don't constrain the generative process. Let the model confabulate freely, then apply external checking.</p>
      </div>
      <div class="principle">
        <div class="principle-title">2. Use document formats as cognitive forcing functions</div>
        <p>Different formats force different kinds of specificity. ToS forces breadth and precision simultaneously.</p>
      </div>
      <div class="principle">
        <div class="principle-title">3. Design for iterative convergence, not one-shot correctness</div>
        <p>Following predictive processing: perception is a rapid predict-compare-update loop. AI tools should support the same.</p>
      </div>
    </div>

  </div>

  <!-- ========== COLUMN 3 ========== -->
  <div class="column">

    <!-- What's Novel -->
    <div class="section">
      <div class="section-title">What's Novel</div>
      <div class="novel-item">No existing tool deliberately exploits hallucination for specification generation</div>
      <div class="novel-item">Only methodology combining AI-generated specs + deliberate hallucination + iterative convergence</div>
      <div class="novel-item">Neuroscience grounding provides design principles, not just metaphors</div>
      <div class="novel-item">Open source: working CLI tool on GitHub (DOI: 10.5281/zenodo.18522644)</div>
    </div>

    <!-- Limitations & Future Work -->
    <div class="section">
      <div class="section-title">Limitations & Future Work</div>
      <p><strong>Limitations:</strong></p>
      <ul>
        <li>Claim quality depends on model training data</li>
        <li>Verification uses LLM (not formal verification)</li>
        <li>Tested on one production application so far</li>
        <li>Developer experience needs formal HCI evaluation</li>
      </ul>
      <p style="margin-top: 8px;"><strong>Future Work:</strong></p>
      <ul>
        <li>User studies comparing developer cognition under LUCID vs. conventional AI-assisted specification</li>
        <li>Measuring specification coverage, cognitive load, and metacognitive awareness</li>
        <li>Multi-document hallucination (API docs, privacy policies, compliance certs)</li>
        <li>CI/CD integration for continuous specification drift detection</li>
        <li>Application beyond software: regulatory compliance, safety certification</li>
      </ul>
    </div>

    <!-- Discussion Questions -->
    <div class="section">
      <div class="section-title">Discussion Questions</div>
      <div class="question">1. How might "hallucination as cognitive resource" change how we design AI development tools?</div>
      <div class="question">2. What other document formats could serve as productive hallucination vehicles?</div>
      <div class="question">3. Can the lucid dreaming metaphor inform interaction design beyond software?</div>
      <div class="question">4. How do we measure whether a tool genuinely augments developer thinking vs. just automating a task?</div>
    </div>

    <!-- References -->
    <div class="section">
      <div class="section-title">References</div>
      <div class="references">
        <p>Anishchenko et al. 2021. De novo protein design by deep network hallucination. <em>Nature</em>.</p>
        <p>Baird et al. 2019. The cognitive neuroscience of lucid dreaming. <em>Neurosci. &amp; Biobehav. Rev.</em></p>
        <p>Banerjee et al. 2024. LLMs Will Always Hallucinate. arXiv:2409.05746.</p>
        <p>Clark 2023. <em>The Experience Machine</em>. Pantheon.</p>
        <p>Friston 2010. The free-energy principle. <em>Nature Rev. Neurosci.</em></p>
        <p>Hirstein 2005. <em>Brain Fiction</em>. MIT Press.</p>
        <p>Huang et al. 2024. LLMs Cannot Self-Correct Reasoning Yet. <em>ICLR</em>.</p>
        <p>Kahneman 2011. <em>Thinking, Fast and Slow</em>.</p>
        <p>Karpowicz 2025. On the Fundamental Impossibility of Hallucination Control in LLMs. arXiv:2506.06382.</p>
        <p>Seth 2021. <em>Being You</em>. Dutton.</p>
        <p>Xu et al. 2024. Hallucination is Inevitable. arXiv:2401.11817.</p>
      </div>
    </div>

  </div>

</div>

<!-- ==================== FOOTER ==================== -->
<footer class="poster-footer">
  <strong>LUCID</strong> &nbsp;|&nbsp; Open Source: github.com/gtsbahamas/hallucination-reversing-system &nbsp;|&nbsp; DOI: 10.5281/zenodo.18522644 &nbsp;|&nbsp; CHI 2026 Tools for Thought Workshop
</footer>

</body>
</html>
